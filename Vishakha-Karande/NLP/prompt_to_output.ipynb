{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f7c530",
   "metadata": {},
   "source": [
    "NLP (Natural Language Processing) enables machines to understand, process and generate in human language\n",
    "**STEP 1 ‚Äî Text Preprocessing (NLP layer)**\n",
    "Purpose: make messy human language machine friendly.\n",
    "\"I Want!!! to Learn ML??\"\n",
    "\"i want to learn ml\"\n",
    "\n",
    "What happens:\n",
    "\n",
    "‚úî lowercase\n",
    "‚úî remove symbols\n",
    "‚úî normalize spacing\n",
    "\n",
    "Why?\n",
    "\n",
    "Machines learn better on clean consistent text.\n",
    "\n",
    "This is classical NLP.\n",
    "\n",
    "**STEP 2 ‚Äî Tokenization (MOST IMPORTANT NLP STEP)**\n",
    "Sentence is broken into small units called tokens.\n",
    "\"i want to learn ml\"\n",
    "‚Üí [\"i\", \"want\", \"to\", \"learn\", \"ml\"]\n",
    "and also used stemming and lemmatization technique\n",
    "to gets the root form of the word like learning - learn\n",
    "\"i want to learn ml\"\n",
    "‚Üí [\"i\", \"want\", \"to\", \"learn\", \"ml\"]\n",
    "\n",
    "**STEP 3 ‚Äî Tokens ‚Üí IDs (machine language)**\n",
    "Model cannot use words.\n",
    "\n",
    "So each token gets a number.\n",
    "\n",
    "i ‚Üí 45\n",
    "want ‚Üí 291\n",
    "learn ‚Üí 1023\n",
    "ml ‚Üí 5541\n",
    "\n",
    "\n",
    "Now sentence becomes:\n",
    "\n",
    "[45, 291, 1023, 5541]\n",
    "\n",
    "\n",
    "This is what neural networks actually see.\n",
    "\n",
    "**STEP 4 ‚Äî Embeddings (THIS IS WHERE MEANING COMES)**\n",
    "Each ID is converted to a vector of numbers.\n",
    "\n",
    "Example (simplified):\n",
    "\n",
    "learn ‚Üí [0.21, 0.89, -0.33, 0.72]\n",
    "study ‚Üí [0.20, 0.85, -0.30, 0.70]\n",
    "\n",
    "\n",
    "Notice:\n",
    "\n",
    "üëâ similar meaning ‚Üí similar vectors\n",
    "\n",
    "This lets model understand:\n",
    "\n",
    "‚Ä¢ context\n",
    "‚Ä¢ similarity\n",
    "‚Ä¢ relationships\n",
    "\n",
    "This is how:\n",
    "\n",
    "king ‚àí man + woman ‚âà queen\n",
    "\n",
    "works.\n",
    "\n",
    "**STEP 5 ‚Äî Transformer Layers (THE BRAIN)**\n",
    "\n",
    "Now the embeddings go through many layers that:\n",
    "\n",
    "‚úî compare words with each other\n",
    "‚úî understand context\n",
    "‚úî focus on important words (attention)\n",
    "\n",
    "Example:\n",
    "\n",
    "In:\n",
    "\n",
    "\"I want to learn ML because it is powerful\"\n",
    "\n",
    "Model learns:\n",
    "\n",
    "‚Äúit‚Äù refers to ML, not ‚Äúlearn‚Äù.\n",
    "\n",
    "This is done using attention mechanism.\n",
    "\n",
    "This is where intelligence happens.\n",
    "\n",
    "**STEP 6 ‚Äî Next Token Prediction**\n",
    "\n",
    "After processing, model outputs:\n",
    "\n",
    "Probabilities of next word.\n",
    "\n",
    "Example:\n",
    "\n",
    "Word\tProbability\n",
    "because\t0.45\n",
    "and\t0.25\n",
    "now\t0.10\n",
    "ml\t0.05\n",
    "\n",
    "Model picks one (smart sampling).\n",
    "\n",
    "üëâ let‚Äôs say it picks ‚Äúbecause‚Äù\n",
    "\n",
    "**STEP 7 ‚Äî Append word**\n",
    "\n",
    "Now sentence becomes:\n",
    "\n",
    "i want to learn ml because\n",
    "\n",
    "**STEP 8 ‚Äî Repeat loop**\n",
    "\n",
    "Model runs again:\n",
    "\n",
    "Predict next word.\n",
    "\n",
    "‚Üí it\n",
    "‚Üí is\n",
    "‚Üí useful\n",
    "‚Üí for\n",
    "‚Üí career\n",
    "\n",
    "\n",
    "Until full answer is formed.\n",
    "\n",
    "=> FINAL OUTPUT\n",
    "i want to learn ml because it is useful for career\n",
    "\n",
    "\n",
    "Stage\t        NLP or DL\n",
    "Cleaning\t    NLP\n",
    "Tokenization\tNLP\n",
    "Vocabulary\t    NLP\n",
    "Embeddings\t    NLP + DL\n",
    "Understanding\tDL (Transformers)\n",
    "Generation\t    DL\n",
    "Looping\t        LLM logic\n",
    "\n",
    "üëâ NLP prepares language\n",
    "üëâ Deep Learning understands & generates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de0215",
   "metadata": {},
   "source": [
    "when we give some text or prompt to the llm \n",
    "for example : I want to learn ML\n",
    "\n",
    "The system does:\n",
    "\n",
    "1. Text Cleaning & Normalization  (NLP)\n",
    "2. Tokenization                  (NLP)\n",
    "3. Token ‚Üí Number IDs            (NLP)\n",
    "4. Embeddings (meaning vectors)  (NLP + DL)\n",
    "5. Transformer processing       (DL)\n",
    "6. Next word probability\n",
    "7. Word generation\n",
    "8. Repeat until full answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae4757",
   "metadata": {},
   "source": [
    "LLMs do only ONE thing repeatedly:\n",
    "predict the NEXT word (token) based on previous ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa57671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to learn ML\n"
     ]
    }
   ],
   "source": [
    "#STEP 1: Take user input (like ChatGPT)\n",
    "text = input(\"Enter your sentence: \")\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97903fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'want', 'to', 'learn', 'ml']\n"
     ]
    }
   ],
   "source": [
    "#STEP 2: Clean the text(Machines don‚Äôt like messy data.)\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return sentence.lower().split()\n",
    "\n",
    "tokens = tokenize(text)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826e6a9",
   "metadata": {},
   "source": [
    "Real LLMs use subword tokens (like ‚Äúlearn‚Äù ‚Üí ‚Äúlea‚Äù + ‚Äúrn‚Äù), but concept is same.\n",
    "\n",
    "STEP 3 ‚Äî CONVERT TOKENS TO NUMBERS (VOCAB ‚Üí IDs)\n",
    "\n",
    "Machines don‚Äôt understand words.\n",
    "\n",
    "They use IDs.\n",
    "\n",
    "Let‚Äôs build a small vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277e311e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"i\": 0,\n",
    "    \"want\": 1,\n",
    "    \"to\": 2,\n",
    "    \"learn\": 3,\n",
    "    \"ml\": 4,\n",
    "    \"ai\": 5,\n",
    "    \"data\": 6,\n",
    "    \"science\": 7\n",
    "}\n",
    "\n",
    "token_ids = [vocab[word] for word in tokens]\n",
    "print(token_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d4a43d",
   "metadata": {},
   "source": [
    "STEP 4 ‚Äî EMBEDDINGS (TURN IDs INTO MEANING VECTORS)\n",
    "\n",
    "Each token becomes a vector (list of numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3aacb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79756861 0.81021973 0.90313224 0.74592373 0.46985764 0.55014048]\n",
      " [0.15901114 0.03386821 0.53725433 0.93507189 0.41795916 0.00219291]\n",
      " [0.56675841 0.57898574 0.97938075 0.68637131 0.40583105 0.30300836]\n",
      " [0.84586997 0.87913169 0.4647663  0.88698237 0.2908476  0.84823793]\n",
      " [0.52750573 0.98897391 0.40134218 0.2773279  0.52968498 0.04267212]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embedding_matrix = np.random.rand(len(vocab), 6)  \n",
    "# 6 = vector size (real LLMs use 4096+)\n",
    "\n",
    "embeddings = embedding_matrix[token_ids]\n",
    "\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04222c02",
   "metadata": {},
   "source": [
    "Words become points in meaning space\n",
    "\n",
    "Similar words ‚Üí close vectors\n",
    "\n",
    "This is how models understand context.\n",
    "\n",
    "STEP 5 ‚Äî TRANSFORMER ‚ÄúTHINKING‚Äù (SIMPLIFIED)\n",
    "\n",
    "Now the model mixes words together.\n",
    "\n",
    "We‚Äôll simulate neural processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2c405",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3721414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.14369583 1.89243445 2.75495311 2.83007481 2.06635834]\n"
     ]
    }
   ],
   "source": [
    "weights = np.random.rand(6)\n",
    "\n",
    "processed = embeddings @ weights\n",
    "print(processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5cf3b4",
   "metadata": {},
   "source": [
    "This:\n",
    "\n",
    "‚Ä¢ multiplies each word vector\n",
    "‚Ä¢ sums info\n",
    "‚Ä¢ creates understanding of sentence\n",
    "\n",
    "This is what deep transformer layers do (just massively bigger).\n",
    "\n",
    "STEP 6 ‚Äî PREDICT NEXT WORD (THE MAGIC)\n",
    "\n",
    "LLMs output probabilities of next token.\n",
    "\n",
    "Let‚Äôs fake a small output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83db7577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0.227\n",
      "want 0.126\n",
      "to 0.129\n",
      "learn 0.153\n",
      "ml 0.101\n",
      "ai 0.084\n",
      "data 0.08\n",
      "science 0.1\n"
     ]
    }
   ],
   "source": [
    "output_weights = np.random.rand(6, len(vocab))\n",
    "\n",
    "logits = processed.mean() * output_weights.mean(axis=0)\n",
    "\n",
    "probabilities = np.exp(logits) / np.sum(np.exp(logits))\n",
    "\n",
    "for word, prob in zip(vocab.keys(), probabilities):\n",
    "    print(word, round(prob, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059bf75",
   "metadata": {},
   "source": [
    "STEP 7 ‚Äî GENERATE NEXT TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c255a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next predicted word: i\n"
     ]
    }
   ],
   "source": [
    "next_word = list(vocab.keys())[np.argmax(probabilities)]\n",
    "print(\"Next predicted word:\", next_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45439321",
   "metadata": {},
   "source": [
    "So now sentence becomes:\n",
    "\n",
    "‚ÄúI want to learn ML ai‚Äù\n",
    "\n",
    "Then model repeats again.\n",
    "\n",
    "Again predicts next.\n",
    "\n",
    "Again.\n",
    "\n",
    "Again.\n",
    "\n",
    "Until full answer forms.\n",
    "It doesn‚Äôt ‚Äúknow answers‚Äù.\n",
    "\n",
    "It does:\n",
    "\n",
    "predict next word thousands of times very smartly\n",
    "\n",
    "while not stop:\n",
    "    tokenize\n",
    "    embed\n",
    "    transform\n",
    "    predict next token\n",
    "    append token\n",
    "\n",
    "WHY LLMs SOUND INTELLIGENT\n",
    "\n",
    "Because:\n",
    "\n",
    "‚úÖ Huge data\n",
    "‚úÖ Huge embeddings\n",
    "‚úÖ Many transformer layers\n",
    "‚úÖ Smart probability selection\n",
    "\n",
    "But core idea = SAME as above.\n",
    "\n",
    "Math + probability + language patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c93d3c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1929675267.py, line 5)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpredict next token\u001b[39m\n            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "while not stop:\n",
    "    tokenize\n",
    "    embed\n",
    "    transform\n",
    "    predict next token\n",
    "    append token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c3f2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Generated Output:\n",
      "i want to learn ml i i i i i i i i i i i i i i i i\n"
     ]
    }
   ],
   "source": [
    "generated_tokens = tokens.copy()   # start with user input\n",
    "generated_tokens.append(next_word)\n",
    "\n",
    "max_length = 15   # how long answer should be\n",
    "\n",
    "for _ in range(max_length):\n",
    "\n",
    "    # convert words to ids again\n",
    "    token_ids = [vocab[word] for word in generated_tokens]\n",
    "\n",
    "    # embeddings\n",
    "    embeddings = embedding_matrix[token_ids]\n",
    "\n",
    "    # combine context\n",
    "    context = embeddings.mean(axis=0)\n",
    "\n",
    "    # predict again\n",
    "    logits = context @ output_weights\n",
    "    probabilities = np.exp(logits) / np.sum(np.exp(logits))\n",
    "\n",
    "    # next word\n",
    "    next_word = list(vocab.keys())[np.argmax(probabilities)]\n",
    "\n",
    "    # stop condition\n",
    "    if next_word == \"end\":\n",
    "        break\n",
    "\n",
    "    generated_tokens.append(next_word)\n",
    "\n",
    "# final output\n",
    "print(\"\\nLLM Generated Output:\")\n",
    "print(\" \".join(generated_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f5dc38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_tokens = tokens.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62102203",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_tokens.append(next_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b38c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
